# 🧠 PDF Chat Assistant  
**Chat with Your PDFs using LangChain, Hugging Face & Streamlit**

Interact naturally with your PDF documents! This beginner-friendly, fully local app leverages **LangChain**, **Hugging Face**, and **Streamlit** to let you upload one or multiple PDFs, ask contextual questions, and receive intelligent, grounded answers — complete with clear source references for full transparency.

---

## 🚀 Key Features

- 📄 **Multi-PDF Upload**  
  Upload single or multiple PDF documents for rich, context-aware Q&A sessions.

- ✂️ **Smart Chunking**  
  Extracts and splits content cleanly using PyMuPDF, optimizing for fast embeddings and retrieval.

- 🧠 **State-of-the-Art Embeddings**  
  Powered by Hugging Face’s Sentence Transformers to capture semantic meaning effectively.

- 📦 **Fast Local Vector Search**  
  Uses FAISS for lightning-fast similarity search — works fully offline on your machine.

- 🤖 **LLM Integration**  
  Answers generated by open-source large language models like Mistral-7B-Instruct via Hugging Face Hub.

- 💬 **Conversational Memory**  
  Maintains dialogue context using LangChain’s memory for smooth and coherent conversations.

- 🗃️ **Source Visibility**  
  Shows the exact PDF source chunks that inform each answer (RAG-style UI).

- 🧠 **Session Logging**  
  Saves your chat history in JSON format for future reference or auditing.

- 🌐 **Elegant Web UI**  
  Built with Streamlit for an intuitive, responsive, and clean user interface.

---

## 🗂️ Project Structure

```plaintext
pdf_chat_assistant/
├── .env                  # 🔐 API keys and config (excluded from Git)
├── .gitignore            # 🚫 Files and folders to ignore
├── README.md             # 📘 Project documentation (this file)
├── requirements.txt      # 📦 Python dependencies
├── app.py                # 🚀 Streamlit app entry point
├── config/
│   └── settings.py       # ⚙️ Environment settings, keys, model configs
├── data/
│   └── uploads/          # 📄 Uploaded PDFs (runtime)
├── src/
│   ├── pdf_loader.py     # 📚 PDF text extractor and chunker
│   ├── rag_chain.py      # 🔍 RAG logic: retrieval + LLM generation
│   ├── memory.py         # 🧠 Conversational memory handler
│   └── utils.py          # 🛠️ Utility functions
├── vectorstore/
│   └── faiss_index/      # 🧬 Local vector index (FAISS)
└── chat_logs/
    └── chat_history.json # 💬 Saved conversations
```

⚙️ Installation & Setup
Follow these steps to get your PDF Chat Assistant running locally:

1. Clone the Repository
```bash

git clone https://github.com/G-Narendra/Pdf-chat-assistant-LLM-Project-.git
cd Pdf-chat-assistant-LLM-Project-
```

2. Create and Activate a Virtual Environment
```bash

python -m venv venv
```
Windows:
```bash

venv\Scripts\activate
```
Linux/macOS:

```bash
source venv/bin/activate
```
3. Install Dependencies
```bash
pip install -r requirements.txt
```
4. Add Your Hugging Face API Token
Create a .env file in the root directory and add your token:

```bash

HUGGINGFACEHUB_API_TOKEN=your_token_here
```
Or run this command:

```bash

echo HUGGINGFACEHUB_API_TOKEN=your_token_here >> .env
🔑 Get your token from Hugging Face Tokens
```

▶️ Running the App
Start the Streamlit server with:

```bash

streamlit run app.py
Open your browser and navigate to http://localhost:8501 to start chatting with your PDFs!
```


# 💡 Example Questions You Can Ask
"What is the main idea of this document?"

"Summarize Section 3 for me."

"What are the steps outlined in the process?"

"Who is the intended audience?"

"Give me an example command mentioned."

# 📌 Requirements
Python 3.8+

Streamlit

LangChain

Hugging Face Transformers & Embeddings

FAISS

PyMuPDF (fitz)

# 🌟 Acknowledgments
LangChain – Language model orchestration framework

Hugging Face – Open-source LLM and embeddings APIs

Streamlit – Rapid web app framework for ML apps

FAISS – Fast similarity search engine

PyMuPDF – PDF text extraction library

